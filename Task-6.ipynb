{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04da2b1f-1183-42ad-b979-ea8906c8b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c280cf-7aab-4973-9c15-0f416b1ae3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d995f63-4ceb-4fba-bf70-eb3fa5c0c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 170M/170M [08:31<00:00, 333kB/s]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259212ef-541d-4335-97a5-97cf1f805a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(tensor):\n",
    "    gray = 0.2989 * tensor[:, 0:1, :, :] + 0.5870 * tensor[:, 1:2, :, :] + 0.1140 * tensor[:, 2:3, :, :]\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eaa8bb7-249d-4718-83ea-316092085933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_hints(gray, color, num_points=10):\n",
    "    B, _, H, W = gray.size()\n",
    "    hint_rgb = torch.zeros_like(color)\n",
    "    hint_mask = torch.zeros((B, 1, H, W), dtype=torch.float32)\n",
    "\n",
    "    for b in range(B):\n",
    "        for _ in range(num_points):\n",
    "            y = torch.randint(0, H, (1,))\n",
    "            x = torch.randint(0, W, (1,))\n",
    "            hint_rgb[b, :, y, x] = color[b, :, y, x]\n",
    "            hint_mask[b, 0, y, x] = 1.0\n",
    "\n",
    "    return hint_rgb, hint_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d2238c-7a5e-4f7a-ac99-f21c19676f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HintColorizationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(5, 64, 3, padding=1),  # 1(gray) + 3(hint_rgb) + 1(hint_mask)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, 3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, gray, hint_rgb, hint_mask):\n",
    "        x = torch.cat([gray, hint_rgb, hint_mask], dim=1)\n",
    "        features = self.encoder(x)\n",
    "        output = self.decoder(features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf67b2c-52b8-444d-8746-459d4bedcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HintColorizationNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "354aa698-ef10-4151-9f0c-7b379c6c6a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Step [0], Loss: 0.2748\n",
      "Epoch [1], Step [100], Loss: 0.0082\n",
      "Epoch [1], Step [200], Loss: 0.0050\n",
      "Epoch [1], Step [300], Loss: 0.0057\n",
      "Epoch [1], Step [400], Loss: 0.0068\n",
      "Epoch [1], Step [500], Loss: 0.0045\n",
      "Epoch [1], Step [600], Loss: 0.0048\n",
      "Epoch [1], Step [700], Loss: 0.0042\n",
      "Epoch [1], Step [800], Loss: 0.0041\n",
      "Epoch [1], Step [900], Loss: 0.0045\n",
      "Epoch [1], Step [1000], Loss: 0.0027\n",
      "Epoch [1], Step [1100], Loss: 0.0033\n",
      "Epoch [1], Step [1200], Loss: 0.0047\n",
      "Epoch [1], Step [1300], Loss: 0.0040\n",
      "Epoch [1], Step [1400], Loss: 0.0069\n",
      "Epoch [1], Step [1500], Loss: 0.0034\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for i, (color, _) in enumerate(trainloader):\n",
    "        color = color.to(device)\n",
    "        gray = rgb_to_grayscale(color).to(device)\n",
    "\n",
    "        hint_rgb, hint_mask = generate_random_hints(gray, color)\n",
    "        hint_rgb = hint_rgb.to(device)\n",
    "        hint_mask = hint_mask.to(device)\n",
    "\n",
    "        output = model(gray, hint_rgb, hint_mask)\n",
    "        loss = criterion(output, color)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f7ee0f3-f922-47f3-8888-432c106fd526",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and unknown targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m         all_preds\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     22\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m---> 24\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(all_labels, all_preds)\n\u001b[0;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     26\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:319\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    225\u001b[0m     {\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    236\u001b[0m ):\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:94\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     96\u001b[0m             type_true, type_pred\n\u001b[0;32m     97\u001b[0m         )\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    101\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and unknown targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for gray_img, true_color in test_loader: \n",
    "        gray_img = gray_img.to(device)\n",
    "        true_color = true_color.to(device)\n",
    "\n",
    "        hint_rgb, hint_mask = generate_random_hints(gray_img, true_color)\n",
    "\n",
    "        output = model(gray_img, hint_rgb.to(device), hint_mask.to(device))\n",
    "\n",
    "        pred_label = torch.argmax(output, dim=1).flatten().cpu().numpy()\n",
    "        true_label = torch.argmax(true_color, dim=1).flatten().cpu().numpy()\n",
    "\n",
    "        all_preds.extend(pred_label)\n",
    "        all_labels.extend(true_label)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro')\n",
    "recall = recall_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Precision (macro):\", precision)\n",
    "print(\"Recall (macro):\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4beadd-34e1-41ce-935d-24ffcbbaeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model.state_dict(), 'colorization_model.pth')\n",
    "\n",
    "torch.save(model, 'colorization_model_full.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a917e-e0c1-40dc-9353-2530bbc225c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_color = next(iter(trainloader))[0][:1].to(device)\n",
    "    sample_gray = rgb_to_grayscale(sample_color)\n",
    "    hint_rgb, hint_mask = generate_random_hints(sample_gray, sample_color)\n",
    "    hint_rgb = hint_rgb.to(device)\n",
    "    hint_mask = hint_mask.to(device)\n",
    "\n",
    "    pred = model(sample_gray.to(device), hint_rgb, hint_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981c9ae-320f-4045-9be3-6efa287ff354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "def show_image(tensor, title=\"\"):\n",
    "    img = tensor.cpu().squeeze()\n",
    "    if img.dim() == 2:\n",
    "        # Grayscale image\n",
    "        plt.imshow(img.numpy(), cmap=\"gray\")\n",
    "    elif img.dim() == 3:\n",
    "        # Color image [C, H, W]\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported tensor shape for visualization\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f56bf-3930-436b-9ce5-5d7d15f78459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sample_gray = torch.rand(1, 64, 64)        \n",
    "hint_rgb = torch.rand(3, 64, 64)          \n",
    "pred = torch.rand(3, 64, 64)                \n",
    "sample_color = torch.rand(3, 64, 64)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa51fb3-9b12-4dfd-a199-994e2afd8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 4, 1); show_image(sample_gray, \"Gray\")\n",
    "plt.subplot(1, 4, 2); show_image(hint_rgb, \"Hint\")\n",
    "plt.subplot(1, 4, 3); show_image(pred, \"Predicted\")\n",
    "plt.subplot(1, 4, 4); show_image(sample_color, \"Original\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa75c3-86a7-4fd7-a78b-d966baa55c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "\n",
    "def colorize_image():\n",
    "    # Load image\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if not file_path:\n",
    "        return\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = Image.open(file_path).convert('RGB').resize((32, 32))\n",
    "    img_tensor = transforms.ToTensor()(img).unsqueeze(0).to(device)\n",
    "    gray = rgb_to_grayscale(img_tensor)\n",
    "    hint_rgb, hint_mask = generate_random_hints(gray, img_tensor)\n",
    "    \n",
    "    # Colorize\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(gray.to(device), hint_rgb.to(device), hint_mask.to(device))\n",
    "    \n",
    "    # Convert to PIL image\n",
    "    output = output.squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "    output = (output * 255).astype(np.uint8)\n",
    "    output_img = Image.fromarray(output)\n",
    "    \n",
    "    # Display\n",
    "    output_img = output_img.resize((256, 256))\n",
    "    output_tk = ImageTk.PhotoImage(output_img)\n",
    "    output_label.config(image=output_tk)\n",
    "    output_label.image = output_tk\n",
    "\n",
    "# Create GUI\n",
    "root = tk.Tk()\n",
    "root.title('Image Colorization')\n",
    "\n",
    "load_button = tk.Button(root, text=\"Load Image\", command=colorize_image)\n",
    "load_button.pack()\n",
    "\n",
    "output_label = tk.Label(root)\n",
    "output_label.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07f507-ca8f-4ff9-b6d8-34cdd85fd473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
