{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09357ea2-75e5-4b22-ab56-02108db6f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e723b632-0ed3-4466-bdcb-974ba7be7bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed2c188-f2f5-4db4-be54-87f8d20bc21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Simple CNN model for colorization\n",
    "class ColorizationNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorizationNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 2, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.tanh(self.conv4(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ebef6-b4f6-4638-af53-196deaa3a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0000\n",
      "Epoch [2/10], Loss: 0.0000\n",
      "Epoch [3/10], Loss: 0.0000\n",
      "Epoch [4/10], Loss: 0.0000\n",
      "Epoch [5/10], Loss: 0.0000\n",
      "Epoch [6/10], Loss: 0.0000\n",
      "Epoch [7/10], Loss: 0.0000\n",
      "Epoch [8/10], Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Dataset preparation and training loop\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((32, 32))\n",
    "])\n",
    "\n",
    "# Using CIFAR-10 as example dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training parameters\n",
    "model = ColorizationNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for i, (inputs, _) in enumerate(train_loader):\n",
    "        # Convert RGB to LAB and get grayscale (L) and color channels (ab)\n",
    "        inputs = inputs.to(device)\n",
    "        gray = inputs[:, 0:1, :, :]  # Using only one channel since grayscale\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(gray)\n",
    "        \n",
    "        loss = criterion(outputs, torch.zeros_like(outputs))  # Placeholder\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Save model weights\n",
    "torch.save(model.state_dict(), 'colorization_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ced38-4638-4264-8199-cddc266113c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ad8605-ee72-4041-bba3-63439033b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluation function (simplified example)\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            gray = inputs[:, 0:1, :, :]\n",
    "            outputs = model(gray)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += 1  # Placeholder for proper evaluation\n",
    "            correct += 1  # Placeholder\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.2%}')\n",
    "    \n",
    "    # Confusion matrix would need proper classification setup\n",
    "    # For colorization, other metrics like PSNR might be more appropriate\n",
    "    return accuracy\n",
    "\n",
    "# Prepare test dataset\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9169706-0e0e-40ea-a89f-d4fa00d4be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, (32, 32))  # assuming CIFAR-10 size\n",
    "    gray_input = gray / 255.0\n",
    "    gray_input = torch.tensor(gray_input).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "    return gray_input, gray\n",
    "\n",
    "def postprocess_output(output, gray_original):\n",
    "    ab = output.squeeze().detach().cpu().numpy().transpose(1, 2, 0)\n",
    "    ab = cv2.resize(ab, (gray_original.shape[1], gray_original.shape[0]))\n",
    "    lab = np.zeros((gray_original.shape[0], gray_original.shape[1], 3))\n",
    "    lab[:, :, 0] = gray_original\n",
    "    lab[:, :, 1:] = ab * 128\n",
    "    bgr = cv2.cvtColor(lab.astype(np.uint8), cv2.COLOR_LAB2BGR)\n",
    "    return bgr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a835a4-1818-4c9f-b491-acfac258e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from threading import Thread\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load models\n",
    "models = {\n",
    "    \"Model A\": ColorizationNet().to(device),\n",
    "    \"Model B\": ColorizationNet().to(device)  # For now same, later load different weights\n",
    "}\n",
    "try:\n",
    "    models[\"Model A\"].load_state_dict(torch.load('model_a_weights.pth'))\n",
    "    models[\"Model B\"].load_state_dict(torch.load('model_b_weights.pth'))\n",
    "    print(\"Loaded model weights successfully\")\n",
    "except:\n",
    "    print(\"Could not load weights, using random initialization\")\n",
    "current_model = list(models.values())[0]\n",
    "cap = cv2.VideoCapture(0)  # Webcam\n",
    "\n",
    "def update_frame():\n",
    "    global current_model\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        gray_input, gray_original = preprocess_frame(frame)\n",
    "        with torch.no_grad():\n",
    "            output = current_model(gray_input)\n",
    "        colorized = postprocess_output(output, gray_original)\n",
    "\n",
    "        cv2.imshow(\"Colorized Video\", colorized)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def switch_model(name):\n",
    "    global current_model\n",
    "    current_model = models[name]\n",
    "\n",
    "# GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Colorization Model Switcher\")\n",
    "tk.Label(root, text=\"Choose Colorization Model:\").pack()\n",
    "\n",
    "for name in models:\n",
    "    btn = tk.Button(root, text=name, command=lambda n=name: switch_model(n))\n",
    "    btn.pack()\n",
    "\n",
    "# Run video capture in a thread\n",
    "thread = Thread(target=update_frame, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f67997e-6e20-43ef-a5cc-221e54b37fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
